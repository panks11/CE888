{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import tensorflow as tf\n",
    "import typing\n",
    "from typing import Any, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file at path D:/DS/Learnin/Essex MS/CE888/git/CE888/assignment2/seq2seq/spider/train_spider.json\n",
      "7000 Rows in Total\n",
      "Reading file at path D:/DS/Learnin/Essex MS/CE888/git/CE888/assignment2/seq2seq/spider/train_others.json\n",
      "8659 Rows in Total\n",
      "Filter Easy Queries\n",
      "Splittin the Train and Test data\n",
      "(727, 7)\n",
      "Data for Training (2908, 7)\n",
      "Data for Testing (727, 7)\n",
      "Sample Vocabulary ['', '[UNK]', 'the', '[start]', '[end]', 'of', '?', '.', 'what', 'are']\n",
      "Sample Vocabulary ['', '[UNK]', 'select', 'from', '[start]', '[end]', 'where', ')', '(', '=']\n"
     ]
    }
   ],
   "source": [
    "handlr = data.Train_Data('D:/DS/Learnin/Essex MS/CE888/git/CE888/assignment2/seq2seq/spider/',['train_spider.json','train_others.json'])\n",
    "input_text_processor = data.Features().vectorizor(handlr.questions , data.Max_Vocab_Size)\n",
    "output_text_processor = data.Features().vectorizor(handlr.sql , data.Max_Vocab_Size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the List of Questions in inp and List of Queries as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = handlr.questions\n",
    "targ = handlr.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(inp)\n",
    "BATCH_SIZE = data.BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = data.embedding_dim\n",
    "units = data.units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "\n",
    "        # The embedding layer converts tokens to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
    "                                                embedding_dim)\n",
    "\n",
    "        # The GRU RNN layer processes those vectors sequentially.\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                    # Return the sequence and state\n",
    "                                    return_sequences=True,\n",
    "                                    return_state=True,\n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, tokens, state=None):\n",
    "        \n",
    "\n",
    "\n",
    "        # 2. The embedding layer looks up the embedding for each token.\n",
    "        vectors = self.embedding(tokens)\n",
    "\n",
    "\n",
    "        # 3. The GRU processes the embedding sequence.\n",
    "        #    output shape: (batch, s, enc_units)\n",
    "        #    state shape: (batch, enc_units)\n",
    "        output, state = self.gru(vectors, initial_state=state)\n",
    "\n",
    "\n",
    "        # 4. Returns the new sequence and its state.\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        # For Eqn. (4), the  Bahdanau attention\n",
    "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "\n",
    "        self.attention = tf.keras.layers.AdditiveAttention()\n",
    "\n",
    "    def call(self, query, value, mask):\n",
    "       \n",
    "        # From Eqn. (4), `W1@ht`.\n",
    "        w1_query = self.W1(query)\n",
    "       \n",
    "        # From Eqn. (4), `W2@hs`.\n",
    "        w2_key = self.W2(value)\n",
    "\n",
    "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
    "        value_mask = mask\n",
    "\n",
    "        context_vector, attention_weights = self.attention(\n",
    "            inputs = [w1_query, value, w2_key],\n",
    "            mask=[query_mask, value_mask],\n",
    "            return_attention_scores = True,\n",
    "        )\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer = BahdanauAttention(units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.dec_units = dec_units\n",
    "    self.output_vocab_size = output_vocab_size\n",
    "    self.embedding_dim = embedding_dim\n",
    "\n",
    "    # For Step 1. The embedding layer convets token IDs to vectors\n",
    "    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
    "                                               embedding_dim)\n",
    "\n",
    "    # For Step 2. The RNN keeps track of what's been generated so far.\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    # For step 3. The RNN output will be the query for the attention layer.\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    # For step 4. Eqn. (3): converting `ct` to `at`\n",
    "    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
    "                                    use_bias=False)\n",
    "\n",
    "    # For step 5. This fully connected layer produces the logits for each\n",
    "    # output token.\n",
    "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderInput(typing.NamedTuple):\n",
    "    new_tokens: Any\n",
    "    enc_output: Any\n",
    "    mask: Any\n",
    "\n",
    "class DecoderOutput(typing.NamedTuple):\n",
    "    logits: Any\n",
    "    attention_weights: Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(self, inputs: DecoderInput, state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
    "\n",
    "  # Step 1. Lookup the embeddings\n",
    "  vectors = self.embedding(inputs.new_tokens)\n",
    " \n",
    "\n",
    "  # Step 2. Process one step with the RNN\n",
    "  rnn_output, state = self.gru(vectors, initial_state=state)\n",
    "\n",
    "  \n",
    "\n",
    "  # Step 3. Use the RNN output as the query for the attention over the\n",
    "  # encoder output.\n",
    "  context_vector, attention_weights = self.attention(\n",
    "      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
    "  \n",
    "\n",
    "  # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
    "  #     [ct; ht] shape: (batch t, value_units + query_units)\n",
    "  context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
    "\n",
    "  # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
    "  attention_vector = self.Wc(context_and_rnn_output)\n",
    "\n",
    "  # Step 5. Generate logit predictions:\n",
    "  logits = self.fc(attention_vector)\n",
    "\n",
    "  return DecoderOutput(logits, attention_weights), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decoder.call = call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
    "                  embedding_dim, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        self.name = 'masked_loss'\n",
    "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True, reduction='none')\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        # Calculate the loss for each item in the batch.\n",
    "        loss = self.loss(y_true, y_pred)\n",
    "\n",
    "        # Mask off the losses on padding.\n",
    "        mask = tf.cast(y_true != 0, tf.float32)\n",
    "        loss *= mask\n",
    "\n",
    "        # Return the total.\n",
    "        return tf.reduce_sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainTranslator(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units,\n",
    "               input_text_processor,\n",
    "               output_text_processor, \n",
    "               use_tf_function=True):\n",
    "        super().__init__()\n",
    "        # Build the encoder and decoder\n",
    "        encoder = Encoder(input_text_processor.vocabulary_size(),\n",
    "                        embedding_dim, units)\n",
    "        decoder = Decoder(output_text_processor.vocabulary_size(),\n",
    "                        embedding_dim, units)\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.input_text_processor = input_text_processor\n",
    "        self.output_text_processor = output_text_processor\n",
    "        self.use_tf_function = use_tf_function\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        if self.use_tf_function:\n",
    "            return self._tf_train_step(inputs)\n",
    "        else:\n",
    "         return self._train_step(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess(self, input_text, target_text):\n",
    "  \n",
    "\n",
    "  # Convert the text to token IDs\n",
    "  input_tokens = self.input_text_processor(input_text)\n",
    "  target_tokens = self.output_text_processor(target_text)\n",
    "  \n",
    "\n",
    "  # Convert IDs to masks.\n",
    "  input_mask = input_tokens != 0\n",
    " \n",
    "\n",
    "  target_mask = target_tokens != 0\n",
    "  \n",
    "\n",
    "  return input_tokens, input_mask, target_tokens, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTranslator._preprocess = _preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_step(self, inputs):\n",
    "    input_text, target_text = inputs  \n",
    "\n",
    "    (input_tokens, input_mask,target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
    "\n",
    "    max_target_length = tf.shape(target_tokens)[1]\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Encode the input\n",
    "        enc_output, enc_state = self.encoder(input_tokens)\n",
    "        \n",
    "\n",
    "        # Initialize the decoder's state to the encoder's final state.\n",
    "        # This only works if the encoder and decoder have the same number of\n",
    "        # units.\n",
    "        dec_state = enc_state\n",
    "        loss = tf.constant(0.0)\n",
    "\n",
    "        for t in tf.range(max_target_length-1):\n",
    "            # Pass in two tokens from the target sequence:\n",
    "            # 1. The current input to the decoder.\n",
    "            # 2. The target for the decoder's next prediction.\n",
    "            new_tokens = target_tokens[:, t:t+2]\n",
    "            step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
    "                                                    enc_output, dec_state)\n",
    "            loss = loss + step_loss\n",
    "\n",
    "    # Average the loss over all non padding tokens.\n",
    "        average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
    "\n",
    "    # Apply an optimization step\n",
    "    variables = self.trainable_variables \n",
    "    gradients = tape.gradient(average_loss, variables)\n",
    "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    # Return a dict mapping metric names to current value\n",
    "    return {'batch_loss': average_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTranslator._train_step = _train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
    "    input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
    "\n",
    "    # Run the decoder one step.\n",
    "    decoder_input = DecoderInput(new_tokens=input_token,\n",
    "                                enc_output=enc_output,\n",
    "                                mask=input_mask)\n",
    "\n",
    "    dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
    "\n",
    "\n",
    "    # `self.loss` returns the total for non-padded tokens\n",
    "    y = target_token\n",
    "    y_pred = dec_result.logits\n",
    "    # print(y_pred.as_numpy_iterator())\n",
    "    step_loss = self.loss(y, y_pred)\n",
    "\n",
    "    return step_loss, dec_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTranslator._loop_step = _loop_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = TrainTranslator(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    "    use_tf_function=False)\n",
    "\n",
    "# Configure the loss and optimizer\n",
    "translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=MaskedLoss(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
    "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
    "def _tf_train_step(self, inputs):\n",
    "  return self._train_step(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTranslator._tf_train_step = _tf_train_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator.use_tf_function = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_translator = TrainTranslator(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor)\n",
    "\n",
    "# Configure the loss and optimizer\n",
    "train_translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=MaskedLoss(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchLogs(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.logs = []\n",
    "\n",
    "    def on_train_batch_end(self, n, logs):\n",
    "        self.logs.append(logs[self.key])\n",
    "\n",
    "batch_loss = BatchLogs('batch_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 126s 3s/step - batch_loss: 4.8429\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 117s 3s/step - batch_loss: 3.0781\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 118s 3s/step - batch_loss: 2.3434\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 118s 3s/step - batch_loss: 2.0450\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 122s 3s/step - batch_loss: 1.8140\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 120s 3s/step - batch_loss: 1.5988\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 127s 3s/step - batch_loss: 1.4064\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 120s 3s/step - batch_loss: 1.2233\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 3720s 83s/step - batch_loss: 1.0401\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 120s 3s/step - batch_loss: 0.8761\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 121s 3s/step - batch_loss: 0.7218\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 118s 3s/step - batch_loss: 0.5983\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 122s 3s/step - batch_loss: 0.4929\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 123s 3s/step - batch_loss: 0.3994\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 123s 3s/step - batch_loss: 0.3214\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 121s 3s/step - batch_loss: 0.2550\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 119s 3s/step - batch_loss: 0.1980\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 121s 3s/step - batch_loss: 0.1534\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 118s 3s/step - batch_loss: 0.1228\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 117s 3s/step - batch_loss: 0.0960\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 120s 3s/step - batch_loss: 0.0757\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 130s 3s/step - batch_loss: 0.0602\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 124s 3s/step - batch_loss: 0.0468\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 125s 3s/step - batch_loss: 0.0387\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 126s 3s/step - batch_loss: 0.0313\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 125s 3s/step - batch_loss: 0.0269\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 133s 3s/step - batch_loss: 0.0210\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 156s 3s/step - batch_loss: 0.0163\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 160s 3s/step - batch_loss: 0.0157\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 158s 3s/step - batch_loss: 0.0136\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 159s 3s/step - batch_loss: 0.0136\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 158s 3s/step - batch_loss: 0.0112\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 159s 3s/step - batch_loss: 0.0118\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 152s 3s/step - batch_loss: 0.0137\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 160s 3s/step - batch_loss: 0.0295\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 158s 3s/step - batch_loss: 0.0599\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 158s 3s/step - batch_loss: 0.0767\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 156s 3s/step - batch_loss: 0.0621\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 158s 3s/step - batch_loss: 0.0423\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 158s 3s/step - batch_loss: 0.0258\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 157s 3s/step - batch_loss: 0.0194\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 159s 3s/step - batch_loss: 0.0114\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 158s 3s/step - batch_loss: 0.0087\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 156s 3s/step - batch_loss: 0.0061\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 152s 3s/step - batch_loss: 0.0054\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 150s 3s/step - batch_loss: 0.0059\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 149s 3s/step - batch_loss: 0.0063\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 149s 3s/step - batch_loss: 0.0066\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 147s 3s/step - batch_loss: 0.0055\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 151s 3s/step - batch_loss: 0.0043\n"
     ]
    }
   ],
   "source": [
    "history = train_translator.fit(dataset, epochs=50, callbacks=[batch_loss,tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Batch Loss')"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(8, 6), dpi=200)\n",
    "plt.plot(batch_loss.logs)\n",
    "plt.ylim([0, 4])\n",
    "plt.xlabel('Batch Number')\n",
    "plt.ylabel('Batch Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.051624774932861,\n",
       " 7.048401832580566,\n",
       " 6.908292770385742,\n",
       " 6.5229058265686035,\n",
       " 5.454949855804443,\n",
       " 8.64066219329834,\n",
       " 7.918764114379883,\n",
       " 6.329209327697754,\n",
       " 6.27166223526001,\n",
       " 5.726656436920166,\n",
       " 5.531042098999023,\n",
       " 5.152456283569336,\n",
       " 4.808164596557617,\n",
       " 4.759221076965332,\n",
       " 4.648735523223877,\n",
       " 4.560144424438477,\n",
       " 4.630853176116943,\n",
       " 4.651496887207031,\n",
       " 4.443292617797852,\n",
       " 4.563898086547852,\n",
       " 4.47241735458374,\n",
       " 4.380863666534424,\n",
       " 4.285150527954102,\n",
       " 4.366373062133789,\n",
       " 4.561182975769043,\n",
       " 4.338625431060791,\n",
       " 4.387815952301025,\n",
       " 4.203274250030518,\n",
       " 4.27259635925293,\n",
       " 4.176522731781006,\n",
       " 4.298745155334473,\n",
       " 4.23585844039917,\n",
       " 4.14679479598999,\n",
       " 4.146397113800049,\n",
       " 4.241480350494385,\n",
       " 4.063497543334961,\n",
       " 4.253663063049316,\n",
       " 3.9712228775024414,\n",
       " 3.9840433597564697,\n",
       " 3.925319194793701,\n",
       " 4.13038444519043,\n",
       " 4.067673206329346,\n",
       " 3.9402806758880615,\n",
       " 3.7709476947784424,\n",
       " 3.8467326164245605,\n",
       " 3.763396739959717,\n",
       " 3.69238018989563,\n",
       " 3.643933057785034,\n",
       " 3.531745433807373,\n",
       " 3.4368627071380615,\n",
       " 3.4303975105285645,\n",
       " 3.5579473972320557,\n",
       " 3.6255416870117188,\n",
       " 3.5068695545196533,\n",
       " 3.490436315536499,\n",
       " 3.4168033599853516,\n",
       " 3.5039985179901123,\n",
       " 3.3774209022521973,\n",
       " 3.3960986137390137,\n",
       " 3.5094428062438965,\n",
       " 3.135533332824707,\n",
       " 3.309101104736328,\n",
       " 3.1752829551696777,\n",
       " 3.2324225902557373,\n",
       " 3.1904232501983643,\n",
       " 3.0934290885925293,\n",
       " 2.8982834815979004,\n",
       " 3.1242523193359375,\n",
       " 3.190814971923828,\n",
       " 3.014552354812622,\n",
       " 2.9887614250183105,\n",
       " 3.0563604831695557,\n",
       " 3.1925244331359863,\n",
       " 2.9073517322540283,\n",
       " 2.8539087772369385,\n",
       " 2.9996352195739746,\n",
       " 2.977917432785034,\n",
       " 2.831576347351074,\n",
       " 2.7299654483795166,\n",
       " 2.822000741958618,\n",
       " 2.874418258666992,\n",
       " 2.8638932704925537,\n",
       " 2.791552782058716,\n",
       " 2.731879711151123,\n",
       " 2.6780924797058105,\n",
       " 2.537353754043579,\n",
       " 2.7489469051361084,\n",
       " 2.717994213104248,\n",
       " 2.5865862369537354,\n",
       " 2.4587998390197754,\n",
       " 2.441784381866455,\n",
       " 2.69832706451416,\n",
       " 2.4378323554992676,\n",
       " 2.457986354827881,\n",
       " 2.4854865074157715,\n",
       " 2.3156301975250244,\n",
       " 2.4093945026397705,\n",
       " 2.301816701889038,\n",
       " 2.5151305198669434,\n",
       " 2.5341639518737793,\n",
       " 2.3576467037200928,\n",
       " 2.3985772132873535,\n",
       " 2.4469923973083496,\n",
       " 2.3080599308013916,\n",
       " 2.2945268154144287,\n",
       " 2.2551984786987305,\n",
       " 2.4736666679382324,\n",
       " 2.3946774005889893,\n",
       " 2.3712804317474365,\n",
       " 2.3143422603607178,\n",
       " 2.4656178951263428,\n",
       " 2.2270095348358154,\n",
       " 2.525722026824951,\n",
       " 2.4246609210968018,\n",
       " 2.3723793029785156,\n",
       " 2.282543182373047,\n",
       " 2.445937395095825,\n",
       " 2.361478805541992,\n",
       " 2.2264907360076904,\n",
       " 2.5216352939605713,\n",
       " 2.408628225326538,\n",
       " 2.190324544906616,\n",
       " 2.234771966934204,\n",
       " 2.25732684135437,\n",
       " 2.2799696922302246,\n",
       " 2.455310344696045,\n",
       " 2.3536295890808105,\n",
       " 2.215470552444458,\n",
       " 2.1868293285369873,\n",
       " 2.267967939376831,\n",
       " 2.319284439086914,\n",
       " 2.162916421890259,\n",
       " 2.240229845046997,\n",
       " 2.4806878566741943,\n",
       " 2.3074958324432373,\n",
       " 2.2273755073547363,\n",
       " 2.074861526489258,\n",
       " 2.276249408721924,\n",
       " 1.9488705396652222,\n",
       " 2.1239850521087646,\n",
       " 1.9990288019180298,\n",
       " 1.889897108078003,\n",
       " 2.14319109916687,\n",
       " 2.0398330688476562,\n",
       " 2.067553758621216,\n",
       " 2.0954113006591797,\n",
       " 2.0056092739105225,\n",
       " 2.1443872451782227,\n",
       " 2.162108898162842,\n",
       " 1.985644817352295,\n",
       " 2.1074023246765137,\n",
       " 1.9865168333053589,\n",
       " 2.1268200874328613,\n",
       " 2.041024684906006,\n",
       " 2.087085485458374,\n",
       " 2.039360284805298,\n",
       " 2.1259491443634033,\n",
       " 2.1703591346740723,\n",
       " 2.0869126319885254,\n",
       " 2.0548510551452637,\n",
       " 1.980600118637085,\n",
       " 2.0380427837371826,\n",
       " 2.001473903656006,\n",
       " 2.2692368030548096,\n",
       " 1.9667103290557861,\n",
       " 2.008185625076294,\n",
       " 1.9754520654678345,\n",
       " 1.8982901573181152,\n",
       " 1.9466170072555542,\n",
       " 2.0510525703430176,\n",
       " 2.0709831714630127,\n",
       " 2.1195321083068848,\n",
       " 2.017657518386841,\n",
       " 1.9124394655227661,\n",
       " 2.0557780265808105,\n",
       " 2.287841558456421,\n",
       " 1.9971774816513062,\n",
       " 1.9994862079620361,\n",
       " 2.0403523445129395,\n",
       " 1.9307752847671509,\n",
       " 2.033874988555908,\n",
       " 1.9935120344161987,\n",
       " 2.015242099761963,\n",
       " 2.0356404781341553,\n",
       " 1.7283456325531006,\n",
       " 1.8624980449676514,\n",
       " 1.8527350425720215,\n",
       " 1.711526870727539,\n",
       " 1.8296966552734375,\n",
       " 1.8585727214813232,\n",
       " 1.7112946510314941,\n",
       " 1.6382309198379517,\n",
       " 1.9909218549728394,\n",
       " 1.7861560583114624,\n",
       " 1.8450349569320679,\n",
       " 1.8470007181167603,\n",
       " 1.7707558870315552,\n",
       " 1.8229273557662964,\n",
       " 1.7755335569381714,\n",
       " 1.8939050436019897,\n",
       " 1.7601773738861084,\n",
       " 1.856889009475708,\n",
       " 1.7575782537460327,\n",
       " 1.8509339094161987,\n",
       " 1.9187074899673462,\n",
       " 1.905036449432373,\n",
       " 1.7632808685302734,\n",
       " 1.6712902784347534,\n",
       " 1.8645873069763184,\n",
       " 1.8326363563537598,\n",
       " 1.7435534000396729,\n",
       " 1.7899315357208252,\n",
       " 1.7874224185943604,\n",
       " 1.753300428390503,\n",
       " 1.7311211824417114,\n",
       " 1.8559999465942383,\n",
       " 1.8080331087112427,\n",
       " 1.7742323875427246,\n",
       " 1.637384295463562,\n",
       " 1.8562533855438232,\n",
       " 1.8559024333953857,\n",
       " 1.9412785768508911,\n",
       " 1.7478795051574707,\n",
       " 1.7149080038070679,\n",
       " 1.8415920734405518,\n",
       " 1.9372756481170654,\n",
       " 1.7782694101333618,\n",
       " 1.7865188121795654,\n",
       " 1.9753525257110596,\n",
       " 1.9183980226516724,\n",
       " 1.535911202430725,\n",
       " 1.5254918336868286,\n",
       " 1.513451337814331,\n",
       " 1.6815814971923828,\n",
       " 1.599242925643921,\n",
       " 1.5550888776779175,\n",
       " 1.6003737449645996,\n",
       " 1.5078834295272827,\n",
       " 1.5292760133743286,\n",
       " 1.558767557144165,\n",
       " 1.5449789762496948,\n",
       " 1.5600905418395996,\n",
       " 1.597561240196228,\n",
       " 1.4954694509506226,\n",
       " 1.6183034181594849,\n",
       " 1.7860307693481445,\n",
       " 1.5990619659423828,\n",
       " 1.689997673034668,\n",
       " 1.6035895347595215,\n",
       " 1.5527533292770386,\n",
       " 1.5130529403686523,\n",
       " 1.5259721279144287,\n",
       " 1.6043235063552856,\n",
       " 1.6697112321853638,\n",
       " 1.5646063089370728,\n",
       " 1.6903473138809204,\n",
       " 1.673935890197754,\n",
       " 1.655457615852356,\n",
       " 1.6279916763305664,\n",
       " 1.596014380455017,\n",
       " 1.7549299001693726,\n",
       " 1.7020223140716553,\n",
       " 1.5744253396987915,\n",
       " 1.6904270648956299,\n",
       " 1.6061413288116455,\n",
       " 1.6372058391571045,\n",
       " 1.6274616718292236,\n",
       " 1.596655011177063,\n",
       " 1.732862114906311,\n",
       " 1.6250718832015991,\n",
       " 1.6061519384384155,\n",
       " 1.6173030138015747,\n",
       " 1.5517208576202393,\n",
       " 1.6145495176315308,\n",
       " 1.47500741481781,\n",
       " 1.4768366813659668,\n",
       " 1.4185749292373657,\n",
       " 1.4144346714019775,\n",
       " 1.3506592512130737,\n",
       " 1.3346470594406128,\n",
       " 1.4945242404937744,\n",
       " 1.3804845809936523,\n",
       " 1.414238691329956,\n",
       " 1.442403793334961,\n",
       " 1.3501724004745483,\n",
       " 1.4823848009109497,\n",
       " 1.3846240043640137,\n",
       " 1.4835790395736694,\n",
       " 1.3424530029296875,\n",
       " 1.2785531282424927,\n",
       " 1.3505316972732544,\n",
       " 1.3644691705703735,\n",
       " 1.3084080219268799,\n",
       " 1.5720608234405518,\n",
       " 1.4038795232772827,\n",
       " 1.4434010982513428,\n",
       " 1.3626855611801147,\n",
       " 1.2672162055969238,\n",
       " 1.356968879699707,\n",
       " 1.500495433807373,\n",
       " 1.386539101600647,\n",
       " 1.5787705183029175,\n",
       " 1.2495999336242676,\n",
       " 1.4833011627197266,\n",
       " 1.4278945922851562,\n",
       " 1.4811551570892334,\n",
       " 1.380323052406311,\n",
       " 1.486452579498291,\n",
       " 1.4838310480117798,\n",
       " 1.4010258913040161,\n",
       " 1.308529019355774,\n",
       " 1.360767126083374,\n",
       " 1.407540202140808,\n",
       " 1.514272928237915,\n",
       " 1.4264826774597168,\n",
       " 1.4767063856124878,\n",
       " 1.438524603843689,\n",
       " 1.389096736907959,\n",
       " 1.3531962633132935,\n",
       " 1.3997550010681152,\n",
       " 1.497363567352295,\n",
       " 1.3342583179473877,\n",
       " 1.1452313661575317,\n",
       " 1.188179612159729,\n",
       " 1.1413742303848267,\n",
       " 1.1686633825302124,\n",
       " 1.2851141691207886,\n",
       " 1.2689927816390991,\n",
       " 1.199784517288208,\n",
       " 1.2495794296264648,\n",
       " 1.2472258806228638,\n",
       " 1.2150070667266846,\n",
       " 1.21939218044281,\n",
       " 1.1555640697479248,\n",
       " 1.1376718282699585,\n",
       " 1.2098137140274048,\n",
       " 1.2752580642700195,\n",
       " 1.3254090547561646,\n",
       " 1.1942002773284912,\n",
       " 1.108488917350769,\n",
       " 1.2351075410842896,\n",
       " 1.1853125095367432,\n",
       " 1.2733263969421387,\n",
       " 1.1893163919448853,\n",
       " 1.217692494392395,\n",
       " 1.3396055698394775,\n",
       " 1.2315016984939575,\n",
       " 1.2705720663070679,\n",
       " 1.2229901552200317,\n",
       " 1.1902716159820557,\n",
       " 1.1646612882614136,\n",
       " 1.2173364162445068,\n",
       " 1.2136372327804565,\n",
       " 1.265838623046875,\n",
       " 1.465065598487854,\n",
       " 1.202816367149353,\n",
       " 1.214009165763855,\n",
       " 1.205299735069275,\n",
       " 1.2358487844467163,\n",
       " 1.1033824682235718,\n",
       " 1.2707871198654175,\n",
       " 1.2364696264266968,\n",
       " 1.278661847114563,\n",
       " 1.1369030475616455,\n",
       " 1.1954164505004883,\n",
       " 1.2777612209320068,\n",
       " 1.3177798986434937,\n",
       " 1.201509714126587,\n",
       " 1.0401334762573242,\n",
       " 0.988813579082489,\n",
       " 0.991867184638977,\n",
       " 1.0374749898910522,\n",
       " 1.1105901002883911,\n",
       " 0.9615745544433594,\n",
       " 1.0676616430282593,\n",
       " 1.0492393970489502,\n",
       " 1.0433343648910522,\n",
       " 1.0787776708602905,\n",
       " 1.0230023860931396,\n",
       " 0.9789096713066101,\n",
       " 1.0181487798690796,\n",
       " 1.1333534717559814,\n",
       " 0.8662722706794739,\n",
       " 1.0546185970306396,\n",
       " 1.019917368888855,\n",
       " 1.0841894149780273,\n",
       " 1.0406211614608765,\n",
       " 1.0130864381790161,\n",
       " 1.018904685974121,\n",
       " 1.025574803352356,\n",
       " 1.0241367816925049,\n",
       " 1.0174049139022827,\n",
       " 1.0863301753997803,\n",
       " 1.085526943206787,\n",
       " 0.9485918879508972,\n",
       " 0.9649778604507446,\n",
       " 1.2197566032409668,\n",
       " 1.033518671989441,\n",
       " 1.1157227754592896,\n",
       " 1.1102473735809326,\n",
       " 0.9988913536071777,\n",
       " 1.0803581476211548,\n",
       " 1.0484647750854492,\n",
       " 1.007044792175293,\n",
       " 1.0919865369796753,\n",
       " 1.0514713525772095,\n",
       " 1.0108752250671387,\n",
       " 1.1383610963821411,\n",
       " 1.0617270469665527,\n",
       " 0.9682461619377136,\n",
       " 1.0273792743682861,\n",
       " 1.0517380237579346,\n",
       " 1.0211727619171143,\n",
       " 1.0376155376434326,\n",
       " 0.7820769548416138,\n",
       " 0.8872270584106445,\n",
       " 0.8612021803855896,\n",
       " 0.8158429861068726,\n",
       " 0.8364415764808655,\n",
       " 0.8602896332740784,\n",
       " 0.845181941986084,\n",
       " 0.9300476312637329,\n",
       " 0.8524247407913208,\n",
       " 0.84316486120224,\n",
       " 0.8481221199035645,\n",
       " 0.9090186357498169,\n",
       " 0.8226470947265625,\n",
       " 0.9215888977050781,\n",
       " 0.8491026163101196,\n",
       " 0.9372493624687195,\n",
       " 0.8910750150680542,\n",
       " 0.8382367491722107,\n",
       " 0.9078782200813293,\n",
       " 0.8561793565750122,\n",
       " 0.8813492059707642,\n",
       " 0.8807578086853027,\n",
       " 0.9541789889335632,\n",
       " 0.8498193621635437,\n",
       " 0.8321474194526672,\n",
       " 0.7491528987884521,\n",
       " 0.9138508439064026,\n",
       " 0.9071987271308899,\n",
       " 0.8348522186279297,\n",
       " 0.8675856590270996,\n",
       " 0.8660946488380432,\n",
       " 0.940664529800415,\n",
       " 0.8609709739685059,\n",
       " 0.8753692507743835,\n",
       " 0.9627483487129211,\n",
       " 0.9060858488082886,\n",
       " 0.851643443107605,\n",
       " 0.8549141883850098,\n",
       " 0.8952471613883972,\n",
       " 0.9115374684333801,\n",
       " 0.900132417678833,\n",
       " 0.847864031791687,\n",
       " 0.8891981244087219,\n",
       " 0.8375675082206726,\n",
       " 0.8197135925292969,\n",
       " 0.9943735003471375,\n",
       " 0.6060716509819031,\n",
       " 0.6422661542892456,\n",
       " 0.6511958241462708,\n",
       " 0.6658895015716553,\n",
       " 0.679561197757721,\n",
       " 0.7158704400062561,\n",
       " 0.6646244525909424,\n",
       " 0.726377010345459,\n",
       " 0.7441176772117615,\n",
       " 0.7224432826042175,\n",
       " 0.7696289420127869,\n",
       " 0.7078956365585327,\n",
       " 0.7707728147506714,\n",
       " 0.7101083993911743,\n",
       " 0.7750182747840881,\n",
       " 0.6924654841423035,\n",
       " 0.7112720608711243,\n",
       " 0.7395608425140381,\n",
       " 0.7877795696258545,\n",
       " 0.6717522740364075,\n",
       " 0.7563508152961731,\n",
       " 0.7162786722183228,\n",
       " 0.7172192931175232,\n",
       " 0.6818839311599731,\n",
       " 0.7754424810409546,\n",
       " 0.7201747894287109,\n",
       " 0.840723991394043,\n",
       " 0.7588136196136475,\n",
       " 0.7308091521263123,\n",
       " 0.7338045239448547,\n",
       " 0.749742865562439,\n",
       " 0.698084831237793,\n",
       " 0.748115062713623,\n",
       " 0.7005419731140137,\n",
       " 0.6630058288574219,\n",
       " 0.7714604139328003,\n",
       " 0.6861684918403625,\n",
       " 0.6653071641921997,\n",
       " 0.7461867332458496,\n",
       " 0.7320912480354309,\n",
       " 0.7682809829711914,\n",
       " 0.7486746311187744,\n",
       " 0.7598220109939575,\n",
       " 0.8322468400001526,\n",
       " 0.7931525111198425,\n",
       " 0.6388705372810364,\n",
       " 0.6155565977096558,\n",
       " 0.5768947601318359,\n",
       " 0.546116828918457,\n",
       " 0.5597176551818848,\n",
       " 0.5253536105155945,\n",
       " 0.5912841558456421,\n",
       " 0.5858394503593445,\n",
       " 0.5635307431221008,\n",
       " 0.5689256191253662,\n",
       " 0.6190176010131836,\n",
       " 0.650532066822052,\n",
       " 0.6515794992446899,\n",
       " 0.5602166056632996,\n",
       " 0.5212726593017578,\n",
       " 0.5386244654655457,\n",
       " 0.6356822848320007,\n",
       " 0.5701479315757751,\n",
       " 0.6262850165367126,\n",
       " 0.7060710191726685,\n",
       " 0.6745471358299255,\n",
       " 0.5404924750328064,\n",
       " 0.5654136538505554,\n",
       " 0.5847092866897583,\n",
       " 0.6306657195091248,\n",
       " 0.5804941058158875,\n",
       " 0.6380680203437805,\n",
       " 0.6539947986602783,\n",
       " 0.5542131066322327,\n",
       " 0.6348975896835327,\n",
       " 0.584627628326416,\n",
       " 0.5997937917709351,\n",
       " 0.5937380194664001,\n",
       " 0.6584171056747437,\n",
       " 0.6206854581832886,\n",
       " 0.5955963134765625,\n",
       " 0.5789535641670227,\n",
       " 0.578291654586792,\n",
       " 0.6325463056564331,\n",
       " 0.6912416815757751,\n",
       " 0.6248672604560852,\n",
       " 0.5741423964500427,\n",
       " 0.6286318302154541,\n",
       " 0.677492082118988,\n",
       " 0.6042484045028687,\n",
       " 0.5721051096916199,\n",
       " 0.5167369842529297,\n",
       " 0.46814653277397156,\n",
       " 0.4396958351135254,\n",
       " 0.45660245418548584,\n",
       " 0.47453975677490234,\n",
       " 0.5314374566078186,\n",
       " 0.47082245349884033,\n",
       " 0.4659220278263092,\n",
       " 0.4994382858276367,\n",
       " 0.4356791377067566,\n",
       " 0.5058021545410156,\n",
       " 0.45632535219192505,\n",
       " 0.6048591732978821,\n",
       " 0.5073041915893555,\n",
       " 0.5258936882019043,\n",
       " 0.47715967893600464,\n",
       " 0.586896538734436,\n",
       " 0.44438788294792175,\n",
       " 0.49599960446357727,\n",
       " 0.4426088035106659,\n",
       " 0.5004734396934509,\n",
       " 0.43714457750320435,\n",
       " 0.5115941762924194,\n",
       " 0.4780704975128174,\n",
       " 0.5139389634132385,\n",
       " 0.4781871438026428,\n",
       " 0.4901900887489319,\n",
       " 0.546367883682251,\n",
       " 0.5454166531562805,\n",
       " 0.48476672172546387,\n",
       " 0.5107749104499817,\n",
       " 0.5603461861610413,\n",
       " 0.5325469970703125,\n",
       " 0.4807659089565277,\n",
       " 0.4479934275150299,\n",
       " 0.44569531083106995,\n",
       " 0.5199058055877686,\n",
       " 0.5493770837783813,\n",
       " 0.46240538358688354,\n",
       " 0.47028419375419617,\n",
       " 0.4971160590648651,\n",
       " 0.5048755407333374,\n",
       " 0.46021753549575806,\n",
       " 0.49180251359939575,\n",
       " 0.544113278388977,\n",
       " 0.46735426783561707,\n",
       " 0.47315752506256104,\n",
       " 0.35804224014282227,\n",
       " 0.3662608861923218,\n",
       " 0.44594743847846985,\n",
       " 0.41259002685546875,\n",
       " 0.33821800351142883,\n",
       " 0.36996808648109436,\n",
       " 0.35864341259002686,\n",
       " 0.3765327036380768,\n",
       " 0.36227527260780334,\n",
       " 0.3691508173942566,\n",
       " 0.4362126588821411,\n",
       " 0.3631206750869751,\n",
       " 0.37267276644706726,\n",
       " 0.4214928448200226,\n",
       " 0.3909929394721985,\n",
       " 0.4220268428325653,\n",
       " 0.36787745356559753,\n",
       " 0.40402281284332275,\n",
       " 0.42902687191963196,\n",
       " 0.45008552074432373,\n",
       " 0.3358616828918457,\n",
       " 0.37502580881118774,\n",
       " 0.43408578634262085,\n",
       " 0.39326098561286926,\n",
       " 0.3946205973625183,\n",
       " 0.34800881147384644,\n",
       " 0.3761940896511078,\n",
       " 0.3928402066230774,\n",
       " 0.4021502733230591,\n",
       " 0.41385939717292786,\n",
       " 0.42661890387535095,\n",
       " 0.4160657227039337,\n",
       " 0.4058545231819153,\n",
       " 0.4118621051311493,\n",
       " 0.412914901971817,\n",
       " 0.518338680267334,\n",
       " 0.4287538230419159,\n",
       " 0.42595404386520386,\n",
       " 0.4077165722846985,\n",
       " 0.44512245059013367,\n",
       " 0.39076557755470276,\n",
       " 0.4654123783111572,\n",
       " 0.3709292709827423,\n",
       " 0.37131017446517944,\n",
       " 0.4176793098449707,\n",
       " 0.38704752922058105,\n",
       " 0.3400688171386719,\n",
       " 0.35889580845832825,\n",
       " 0.2897503674030304,\n",
       " 0.298482745885849,\n",
       " 0.30907654762268066,\n",
       " 0.248632550239563,\n",
       " 0.30112984776496887,\n",
       " 0.31646910309791565,\n",
       " 0.32143932580947876,\n",
       " 0.28359028697013855,\n",
       " 0.34164881706237793,\n",
       " 0.28976690769195557,\n",
       " 0.2777842879295349,\n",
       " 0.3395008444786072,\n",
       " 0.3119281828403473,\n",
       " 0.2975405156612396,\n",
       " 0.2916087806224823,\n",
       " 0.3154858350753784,\n",
       " 0.3409556746482849,\n",
       " 0.29892539978027344,\n",
       " 0.325128436088562,\n",
       " 0.33080339431762695,\n",
       " 0.3064567446708679,\n",
       " 0.3434503674507141,\n",
       " 0.3672501742839813,\n",
       " 0.324136346578598,\n",
       " 0.3019908666610718,\n",
       " 0.34068867564201355,\n",
       " 0.298820823431015,\n",
       " 0.3307231664657593,\n",
       " 0.3400646448135376,\n",
       " 0.2843112349510193,\n",
       " 0.3158112168312073,\n",
       " 0.3607209026813507,\n",
       " 0.30930620431900024,\n",
       " 0.31376031041145325,\n",
       " 0.3739597797393799,\n",
       " 0.3283163011074066,\n",
       " 0.36024728417396545,\n",
       " 0.3344534635543823,\n",
       " 0.3488830029964447,\n",
       " 0.30355170369148254,\n",
       " 0.3299176096916199,\n",
       " 0.3105131983757019,\n",
       " 0.3713945150375366,\n",
       " 0.33922824263572693,\n",
       " 0.22336241602897644,\n",
       " 0.2360774576663971,\n",
       " 0.22253942489624023,\n",
       " 0.23170018196105957,\n",
       " 0.20286917686462402,\n",
       " 0.24696898460388184,\n",
       " 0.23915432393550873,\n",
       " 0.2569713592529297,\n",
       " 0.27730685472488403,\n",
       " 0.26713883876800537,\n",
       " 0.26064857840538025,\n",
       " 0.24786409735679626,\n",
       " 0.2752135097980499,\n",
       " 0.2227199226617813,\n",
       " 0.2825482189655304,\n",
       " 0.2618219554424286,\n",
       " 0.242655411362648,\n",
       " 0.23937347531318665,\n",
       " 0.2540149688720703,\n",
       " 0.24638040363788605,\n",
       " 0.2778407335281372,\n",
       " 0.3086299002170563,\n",
       " 0.24525441229343414,\n",
       " 0.2425277829170227,\n",
       " 0.24632999300956726,\n",
       " 0.2520732581615448,\n",
       " 0.2618217170238495,\n",
       " 0.24796979129314423,\n",
       " 0.2289082407951355,\n",
       " 0.2534090578556061,\n",
       " 0.2644352316856384,\n",
       " 0.2604921758174896,\n",
       " 0.23752501606941223,\n",
       " 0.30606985092163086,\n",
       " 0.2709723114967346,\n",
       " 0.23474232852458954,\n",
       " 0.3029481768608093,\n",
       " 0.26607462763786316,\n",
       " 0.20935094356536865,\n",
       " 0.23531387746334076,\n",
       " 0.2688525915145874,\n",
       " 0.29768750071525574,\n",
       " 0.24164490401744843,\n",
       " 0.25630444288253784,\n",
       " 0.2925727367401123,\n",
       " 0.2698366940021515,\n",
       " 0.18987315893173218,\n",
       " 0.16700077056884766,\n",
       " 0.22121316194534302,\n",
       " 0.17961470782756805,\n",
       " 0.19682593643665314,\n",
       " 0.17305588722229004,\n",
       " 0.1584433615207672,\n",
       " 0.21718475222587585,\n",
       " 0.18489199876785278,\n",
       " 0.19668181240558624,\n",
       " 0.19273151457309723,\n",
       " 0.20211297273635864,\n",
       " 0.19016462564468384,\n",
       " 0.1953018456697464,\n",
       " 0.1781027764081955,\n",
       " 0.1933722347021103,\n",
       " 0.18111012876033783,\n",
       " 0.19671379029750824,\n",
       " 0.2017238587141037,\n",
       " 0.19837333261966705,\n",
       " 0.21861407160758972,\n",
       " 0.1786155253648758,\n",
       " 0.2004946619272232,\n",
       " 0.19297374784946442,\n",
       " 0.168813556432724,\n",
       " 0.24441833794116974,\n",
       " 0.19716694951057434,\n",
       " 0.19279512763023376,\n",
       " 0.20685334503650665,\n",
       " 0.21231135725975037,\n",
       " 0.19136299192905426,\n",
       " 0.17993634939193726,\n",
       " 0.1894383281469345,\n",
       " 0.1835183948278427,\n",
       " 0.18277306854724884,\n",
       " 0.195730522274971,\n",
       " 0.21931041777133942,\n",
       " 0.20997820794582367,\n",
       " 0.24028468132019043,\n",
       " 0.24424518644809723,\n",
       " 0.19518540799617767,\n",
       " 0.23069365322589874,\n",
       " 0.24900543689727783,\n",
       " 0.18347017467021942,\n",
       " 0.20767401158809662,\n",
       " 0.1887432187795639,\n",
       " 0.13020649552345276,\n",
       " 0.15684741735458374,\n",
       " 0.14676865935325623,\n",
       " 0.1368359923362732,\n",
       " 0.1527252197265625,\n",
       " 0.1353883594274521,\n",
       " 0.16024059057235718,\n",
       " 0.1712166666984558,\n",
       " 0.15354779362678528,\n",
       " 0.13776558637619019,\n",
       " 0.16900929808616638,\n",
       " 0.15076884627342224,\n",
       " 0.16248995065689087,\n",
       " 0.1368570476770401,\n",
       " 0.15642693638801575,\n",
       " 0.14944128692150116,\n",
       " 0.1698388159275055,\n",
       " 0.1803298145532608,\n",
       " 0.14179806411266327,\n",
       " 0.16302113234996796,\n",
       " 0.12470337003469467,\n",
       " 0.16941632330417633,\n",
       " 0.16163557767868042,\n",
       " 0.15144498646259308,\n",
       " 0.13613660633563995,\n",
       " 0.15580515563488007,\n",
       " 0.17110654711723328,\n",
       " 0.1414238065481186,\n",
       " 0.13575486838817596,\n",
       " 0.1714363694190979,\n",
       " 0.13536851108074188,\n",
       " 0.16779416799545288,\n",
       " 0.15886612236499786,\n",
       " 0.1423337459564209,\n",
       " 0.1603117436170578,\n",
       " 0.15067681670188904,\n",
       " 0.15650077164173126,\n",
       " 0.15174171328544617,\n",
       " 0.17904405295848846,\n",
       " 0.19216148555278778,\n",
       " 0.1690872758626938,\n",
       " 0.14796458184719086,\n",
       " 0.1567162275314331,\n",
       " 0.17094293236732483,\n",
       " 0.13999155163764954,\n",
       " 0.12530195713043213,\n",
       " 0.08709749579429626,\n",
       " 0.10638059675693512,\n",
       " 0.09155071526765823,\n",
       " 0.12501801550388336,\n",
       " 0.1157815232872963,\n",
       " 0.10762307047843933,\n",
       " 0.11938294768333435,\n",
       " 0.12807407975196838,\n",
       " 0.11996911466121674,\n",
       " 0.13632386922836304,\n",
       " 0.12825092673301697,\n",
       " 0.11061662435531616,\n",
       " 0.12254523485898972,\n",
       " 0.10326611995697021,\n",
       " 0.10421637445688248,\n",
       " 0.12950211763381958,\n",
       " 0.13923147320747375,\n",
       " 0.1149134561419487,\n",
       " 0.12917059659957886,\n",
       " 0.13198146224021912,\n",
       " 0.12478919327259064,\n",
       " 0.1169690415263176,\n",
       " 0.13211728632450104,\n",
       " 0.11836855113506317,\n",
       " 0.11311608552932739,\n",
       " 0.10447042435407639,\n",
       " 0.11733793467283249,\n",
       " 0.15347401797771454,\n",
       " 0.13347500562667847,\n",
       " 0.11639124900102615,\n",
       " 0.12655895948410034,\n",
       " 0.1261157989501953,\n",
       " 0.12129944562911987,\n",
       " 0.10643107444047928,\n",
       " 0.136415034532547,\n",
       " 0.116417795419693,\n",
       " 0.16374868154525757,\n",
       " 0.12168525159358978,\n",
       " 0.13212135434150696,\n",
       " 0.11671800911426544,\n",
       " 0.10499731451272964,\n",
       " 0.15526974201202393,\n",
       " 0.17014893889427185,\n",
       " 0.12686994671821594,\n",
       " 0.13715772330760956,\n",
       " 0.11514867842197418,\n",
       " 0.06966620683670044,\n",
       " 0.08021767437458038,\n",
       " 0.08146627247333527,\n",
       " 0.08787454664707184,\n",
       " 0.08999686688184738,\n",
       " 0.08844436705112457,\n",
       " 0.07464811205863953,\n",
       " 0.10082685947418213,\n",
       " 0.086742103099823,\n",
       " 0.0809723362326622,\n",
       " 0.10152210295200348,\n",
       " 0.10384954512119293,\n",
       " 0.0976659506559372,\n",
       " 0.10430818796157837,\n",
       " 0.0834665447473526,\n",
       " 0.08702436089515686,\n",
       " 0.12424042820930481,\n",
       " 0.0762983039021492,\n",
       " 0.09628339111804962,\n",
       " 0.10595032572746277,\n",
       " 0.09036505222320557,\n",
       " 0.08863317966461182,\n",
       " 0.07705289870500565,\n",
       " 0.12811379134655,\n",
       " 0.08663631975650787,\n",
       " 0.10591764003038406,\n",
       " 0.08487275242805481,\n",
       " 0.09231065958738327,\n",
       " 0.09331534057855606,\n",
       " 0.10335766524076462,\n",
       " 0.11026023328304291,\n",
       " 0.09129251539707184,\n",
       " 0.10266480594873428,\n",
       " 0.09763427823781967,\n",
       " 0.10658043622970581,\n",
       " 0.08985824137926102,\n",
       " 0.09677929431200027,\n",
       " 0.1099269911646843,\n",
       " 0.10947459936141968,\n",
       " 0.10082772374153137,\n",
       " 0.09080665558576584,\n",
       " 0.08579132705926895,\n",
       " 0.10366754978895187,\n",
       " 0.11018858104944229,\n",
       " 0.10933475196361542,\n",
       " 0.11309868842363358,\n",
       " 0.06266819685697556,\n",
       " 0.06876122206449509,\n",
       " 0.06935232877731323,\n",
       " 0.08144248276948929,\n",
       " 0.06804515421390533,\n",
       " 0.09669020026922226,\n",
       " 0.0803757756948471,\n",
       " 0.06451163440942764,\n",
       " 0.06661234050989151,\n",
       " 0.0707564651966095,\n",
       " 0.0796087384223938,\n",
       " 0.08691960573196411,\n",
       " 0.06948728114366531,\n",
       " 0.058838117867708206,\n",
       " 0.07023841142654419,\n",
       " 0.07613259553909302,\n",
       " 0.066282719373703,\n",
       " 0.09135723114013672,\n",
       " 0.08671200275421143,\n",
       " 0.06773321330547333,\n",
       " 0.08195102959871292,\n",
       " 0.0683397650718689,\n",
       " 0.0673523098230362,\n",
       " 0.06171059235930443,\n",
       " 0.06308432668447495,\n",
       " 0.07566051930189133,\n",
       " 0.07111886143684387,\n",
       " 0.06827061623334885,\n",
       " 0.054829392582178116,\n",
       " 0.07826936990022659,\n",
       " 0.0987461730837822,\n",
       " 0.08977311104536057,\n",
       " 0.06814117729663849,\n",
       " 0.08736352622509003,\n",
       " 0.07271470874547958,\n",
       " 0.0779830813407898,\n",
       " 0.08031505346298218,\n",
       " 0.06828225404024124,\n",
       " 0.08291908353567123,\n",
       " 0.07634249329566956,\n",
       " 0.07662085443735123,\n",
       " 0.07722622901201248,\n",
       " 0.09256313741207123,\n",
       " 0.08063061535358429,\n",
       " 0.09139800071716309,\n",
       " 0.0826098844408989,\n",
       " 0.04661701247096062,\n",
       " 0.05606332793831825,\n",
       " 0.04206058755517006,\n",
       " 0.060659218579530716,\n",
       " 0.052132636308670044,\n",
       " 0.050632815808057785,\n",
       " 0.061092592775821686,\n",
       " 0.0513133630156517,\n",
       " 0.05562075972557068,\n",
       " 0.04656831920146942,\n",
       " 0.06659554690122604,\n",
       " 0.055995479226112366,\n",
       " 0.07898817211389542,\n",
       " 0.05520697683095932,\n",
       " 0.05301579833030701,\n",
       " 0.05767161026597023,\n",
       " 0.05279683694243431,\n",
       " 0.07279936224222183,\n",
       " 0.06931841373443604,\n",
       " 0.05346936732530594,\n",
       " 0.08698362112045288,\n",
       " 0.05588797479867935,\n",
       " 0.06455879658460617,\n",
       " 0.07351373136043549,\n",
       " 0.05989997833967209,\n",
       " 0.051755622029304504,\n",
       " 0.06000736728310585,\n",
       " 0.08421657979488373,\n",
       " 0.06506482511758804,\n",
       " 0.05577487125992775,\n",
       " 0.06094928830862045,\n",
       " 0.05369436740875244,\n",
       " 0.05391847714781761,\n",
       " 0.05162756145000458,\n",
       " ...]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss.logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "    \n",
    "  def __init__(self, encoder, decoder, input_text_processor,\n",
    "               output_text_processor):\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    self.input_text_processor = input_text_processor\n",
    "    self.output_text_processor = output_text_processor\n",
    "\n",
    "    self.output_token_string_from_index = (\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=output_text_processor.get_vocabulary(),\n",
    "            mask_token='',\n",
    "            invert=True))\n",
    "\n",
    "    # The output should never generate padding, unknown, or start.\n",
    "    index_from_string = tf.keras.layers.StringLookup(\n",
    "        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
    "    token_mask_ids = index_from_string(['', '[unk]', '[start]']).numpy()\n",
    "\n",
    "    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
    "    token_mask[np.array(token_mask_ids)] = True\n",
    "    self.token_mask = token_mask\n",
    "\n",
    "    self.start_token = index_from_string(tf.constant('[start]'))\n",
    "    self.end_token = index_from_string(tf.constant('[end]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "translator = Translator(\n",
    "    encoder=train_translator.encoder,\n",
    "    decoder=train_translator.decoder,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_text(self, result_tokens):\n",
    "    \n",
    "    result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
    "   \n",
    "\n",
    "    result_text = tf.strings.reduce_join(result_text_tokens,\n",
    "                                        axis=1, separator=' ')\n",
    "    \n",
    "\n",
    "    result_text = tf.strings.strip(result_text)\n",
    "    \n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "Translator.tokens_to_text = tokens_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_output_tokens = tf.random.uniform(\n",
    "#     shape=[5, 2], minval=0, dtype=tf.int64,\n",
    "#     maxval=output_text_processor.vocabulary_size())\n",
    "# translator.tokens_to_text(example_output_tokens).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(self, logits, temperature):\n",
    "\n",
    "    token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
    "    logits = tf.where(self.token_mask, -np.inf, logits)\n",
    "\n",
    "    if temperature == 0.0:\n",
    "        new_tokens = tf.argmax(logits, axis=-1)\n",
    "    else: \n",
    "        logits = tf.squeeze(logits, axis=1)\n",
    "        new_tokens = tf.random.categorical(logits/temperature,\n",
    "                                            num_samples=1)\n",
    "\n",
    "    return new_tokens\n",
    "\n",
    "Translator.sample = sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
       "array([[ 661],\n",
       "       [ 323],\n",
       "       [ 738],\n",
       "       [ 911],\n",
       "       [1866]], dtype=int64)>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_logits = tf.random.normal([5, 1, output_text_processor.vocabulary_size()])\n",
    "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
    "example_output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_unrolled(self,\n",
    "                       input_text, *,\n",
    "                       max_length=50,\n",
    "                       return_attention=True,\n",
    "                       temperature=1.0):\n",
    "  batch_size = tf.shape(input_text)[0]\n",
    "  input_tokens = self.input_text_processor(input_text)\n",
    "  enc_output, enc_state = self.encoder(input_tokens)\n",
    "\n",
    "  dec_state = enc_state\n",
    "  new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
    "\n",
    "  result_tokens = []\n",
    "  attention = []\n",
    "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "\n",
    "  for _ in range(max_length):\n",
    "    dec_input = DecoderInput(new_tokens=new_tokens,\n",
    "                             enc_output=enc_output,\n",
    "                             mask=(input_tokens!=0))\n",
    "\n",
    "    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
    "\n",
    "    attention.append(dec_result.attention_weights)\n",
    "\n",
    "    new_tokens = self.sample(dec_result.logits, temperature)\n",
    "\n",
    "    # If a sequence produces an `end_token`, set it `done`\n",
    "    done = done | (new_tokens == self.end_token)\n",
    "    # Once a sequence is done it only produces 0-padding.\n",
    "    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
    "\n",
    "    # Collect the generated tokens\n",
    "    result_tokens.append(new_tokens)\n",
    "\n",
    "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
    "      break\n",
    "\n",
    "  # Convert the list of generates token ids to a list of strings.\n",
    "  result_tokens = tf.concat(result_tokens, axis=-1)\n",
    "  result_text = self.tokens_to_text(result_tokens)\n",
    "\n",
    "  if return_attention:\n",
    "    attention_stack = tf.concat(attention, axis=1)\n",
    "    return {'text': result_text, 'attention': attention_stack}\n",
    "  else:\n",
    "    return {'text': result_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "Translator.translate = translate_unrolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select count ( * ) from event\n",
      "sum select count ( * ) from department )\n",
      "\n",
      "Wall time: 245 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_text = tf.constant([\n",
    "    'How many singers do we have?', # \"It's really cold here.\"\n",
    "    'What is the total number of singers?', # \"This is my life.\"\"\n",
    "])\n",
    "\n",
    "result = translator.translate(\n",
    "    input_text = input_text)\n",
    "\n",
    "print(result['text'][0].numpy().decode())\n",
    "print(result['text'][1].numpy().decode())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select count ( * ) from team_franchise where active = 'y';\n",
      "select count ( * ) from products where product_category_code = \"spices\" and typical_buying_price > 1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = list(handlr.df_test['question'].values)\n",
    "\n",
    "input_text = tf.constant(test)\n",
    "\n",
    "result = translator.translate(\n",
    "    input_text = input_text)\n",
    "\n",
    "print(result['text'][0].numpy().decode())\n",
    "print(result['text'][1].numpy().decode())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = handlr.df_test['query'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 33.56 %\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(test)):\n",
    "    # print(test[i])\n",
    "    # print(\"Predicted\")\n",
    "    pred = result['text'][i].numpy().decode().lower().replace(' ','')\n",
    "    # print(pred)\n",
    "    # print(\"Actual\")\n",
    "    act = query[i].lower().replace(' ','')\n",
    "    # print(act)\n",
    "    if pred == act:\n",
    "        count = count +1\n",
    "print(\"Accuracy is {:.2f} %\".format(count*100/len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_2022_04_25-13_08_09"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24c7168f742075337832b93c1fbfd4355e111387279ce758eae35d9b42cad7f4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
